{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -qUq onnxruntime opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -qU git+https://github.com/ZFTurbo/Weighted-Boxes-Fusion.git#egg=ensemble_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -e git+https://github.com/Shining-Future/project-p-inference.git#egg=projectp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os import path as osp\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "\n",
    "PATH_DATA = '../data/beta'\n",
    "PATH_MODELS = '../models'\n",
    "NAME_MODEL = 'best.onnx'\n",
    "\n",
    "SIZE = 512\n",
    "OFFSET_X = 2\n",
    "OFFSET_Y = 3\n",
    "\n",
    "PATCH = np.s_[OFFSET_X * SIZE:OFFSET_X * SIZE + SIZE, OFFSET_Y * SIZE:OFFSET_Y * SIZE + SIZE, ...]\n",
    "\n",
    "# session = onnxruntime.InferenceSession(osp.join(PATH_MODELS, NAME_MODEL))\n",
    "\n",
    "# for filename in sorted(glob(osp.join(PATH_DATA, '*'))):\n",
    "#     video = cv.VideoCapture(filename)\n",
    "#     if video.isOpened():\n",
    "#         while True:\n",
    "#             ok, frame = video.read()\n",
    "#             if not ok:\n",
    "#                 break\n",
    "#             image = cv.cvtColor(frame[PATCH], cv.COLOR_BGR2RGB)\n",
    "#             batch = np.moveaxis(image, -1, 0)[None, ...] / np.float32(255)\n",
    "#             boxes = session.run(None, {session.get_inputs()[0].name: batch})[0][0]\n",
    "#             break\n",
    "#     video.release()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(1024 / 72, 1024 / 72), dpi=72)\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes[:, 4].argsort()[::-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes[boxes[:, 4].argsort()[::-1][:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from projectp.utils import nms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes_abs = boxes.copy()\n",
    "\n",
    "# # boxes_abs[0]\n",
    "\n",
    "# boxes_abs[:, 0] -= boxes_abs[:, 2] / 2\n",
    "# boxes_abs[:, 1] -= boxes_abs[:, 3] / 2\n",
    "\n",
    "# boxes_abs[:, 2] += boxes_abs[:, 0]\n",
    "# boxes_abs[:, 3] += boxes_abs[:, 1]\n",
    "\n",
    "# # boxes_abs[:, :4] *= SIZE\n",
    "\n",
    "# boxes_abs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# indices = nms(boxes_abs[:, :4], boxes_abs[:, 4], 0.175)\n",
    "\n",
    "# len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes[indices][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes[indices][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRESHOLD_BBOXES = 0.010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes_sorted = boxes_abs[indices]\n",
    "\n",
    "# len(boxes_sorted[boxes_sorted[:, 4] >= THRESHOLD_BBOXES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import patches\n",
    "\n",
    "\n",
    "# figure, axes = plt.subplots(figsize=(1024 / 72, 1024 / 72), dpi=72)\n",
    "# axes.imshow(image)\n",
    "# for bbox in boxes_sorted[boxes_sorted[:, 4] >= THRESHOLD_BBOXES]:\n",
    "#     axes.add_patch(patches.Rectangle(bbox[:2], *(bbox[2:4] - bbox[:2]), linewidth=1,\n",
    "#                                      edgecolor='pink', facecolor='none'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from ensemble_boxes import nms, weighted_boxes_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes_norm = boxes.copy()\n",
    "\n",
    "# # Normalizing to 0..1 absolute\n",
    "\n",
    "# boxes_norm[:, 0] -= boxes_norm[:, 2] / 2\n",
    "# boxes_norm[:, 1] -= boxes_norm[:, 3] / 2\n",
    "\n",
    "# boxes_norm[:, 2] += boxes_norm[:, 0]\n",
    "# boxes_norm[:, 3] += boxes_norm[:, 1]\n",
    "\n",
    "# boxes_norm[:, 0:4:2] /= image.shape[1]\n",
    "# boxes_norm[:, 1:4:2] /= image.shape[0]\n",
    "\n",
    "# boxes_norm[1612]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes_norm[:, :4][boxes_norm[:, :4] < 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes_nms = nms(np.clip(boxes_norm[:, :4][None, ...], 0, 1),\n",
    "#                 boxes_norm[:, 4][None, ...],\n",
    "#                 boxes_norm[:, 5][None, ...].round(),\n",
    "#                 0.175)\n",
    "\n",
    "# boxes_nms = np.column_stack(boxes_nms)\n",
    "\n",
    "\n",
    "# # Denormalizing\n",
    "# boxes_nms[:, 0:4:2] *= image.shape[1]\n",
    "# boxes_nms[:, 1:4:2] *= image.shape[0]\n",
    "\n",
    "# boxes_nms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import patches\n",
    "\n",
    "\n",
    "# figure, axes = plt.subplots(figsize=(1024 / 72, 1024 / 72), dpi=72)\n",
    "# axes.imshow(image)\n",
    "# for bbox in boxes_nms[boxes_nms[:, 4] >= THRESHOLD_BBOXES]:\n",
    "#     axes.add_patch(patches.Rectangle(bbox[:2], *(bbox[2:4] - bbox[:2]), linewidth=1,\n",
    "#                                      edgecolor='pink', facecolor='none'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from projectp.processing import get_tiles, draw_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from projectp.processing import yolo_to_xyxy, absolute_to_relative, relative_to_absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tiles = get_tiles(frame, (SIZE, SIZE), verbose=True)\n",
    "\n",
    "# tiles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !7z -tzip projectp.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class ProgressStub(tuple):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         ...\n",
    "\n",
    "# tqdm_ = ProgressStub\n",
    "\n",
    "# for i in tqdm_(range(5), position=0, leave=True, disable=False):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from matplotlib import cm, colors\n",
    "\n",
    "\n",
    "# # detections = boxes_nms_absolute\n",
    "\n",
    "# def get_colors(detections):\n",
    "#     cmap = plt.get_cmap('gist_rainbow')\n",
    "#     cnorm = colors.Normalize(0, len(detections))\n",
    "\n",
    "#     return cm.ScalarMappable(norm=cnorm, cmap=cmap)\n",
    "\n",
    "# def draw_detections(frame, detections, font_face=cv.FONT_HERSHEY_COMPLEX_SMALL, font_scale=2, font_thickness=3,\n",
    "#                     text_origin_x=None, text_origin_y=None):\n",
    "#     scma = get_colors(detections)  # TODO: replcae with numpy array\n",
    "\n",
    "#     # frame = frame.copy()\n",
    "#     # detections = detections.copy()\n",
    "#     coords_all = detections[..., 0:2] + (detections[..., 2:4] - detections[..., 0:2]) / 2\n",
    "#     # for i, detection in enumerate(detections):  # boxes_total[0]:\n",
    "#     for i, coords in enumerate(coords_all):\n",
    "#         # coords = detection[0:2] + (detection[2:4] - detection[0:2]) / 2\n",
    "#         color = (np.array(scma.to_rgba(i)[:3]) * 255).round().astype('uint8').tolist()\n",
    "#         frame = cv.circle(frame, (coords.round().astype('int')), radius=2, color=color, thickness=2)\n",
    "#     text = f\"Detected: {len(detections)}\"\n",
    "#     text_size = cv.getTextSize(text, font_face, font_scale, font_thickness)\n",
    "#     text_origin = text_origin_x or 32, text_origin_y or text_size[0][1] * 1.5\n",
    "\n",
    "#     cv.putText(frame, text, tuple(map(lambda x: round(x + 1), text_origin)),\n",
    "#                font_face, font_scale, (0, 0, 0), font_thickness, 8)\n",
    "#     cv.putText(frame, text, tuple(map(lambda x: round(x), text_origin)),\n",
    "#                font_face, font_scale, (255, 255, 255), font_thickness, 8)\n",
    "#     return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes_video = np.random.randn(0, 6)\n",
    "\n",
    "# boxes_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.insert(boxes_video, 0, 1, -1)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.concatenate([boxes_video, boxes_video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len({1:1, 2:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from time import perf_counter\n",
    "\n",
    "# try:\n",
    "#     from tqdm import tqdm\n",
    "# except ImportError:\n",
    "#     class ProgressStub(tuple):\n",
    "#         def __init__(self, *args, **kwargs):\n",
    "#             ...\n",
    "\n",
    "#     tqdm = ProgressStub\n",
    "\n",
    "\n",
    "# class InferenceONNX:\n",
    "#     def __init__(self, path, prefix):\n",
    "#         \"\"\"\n",
    "#         path: path to the model to predict from (a single model)\n",
    "#         prefix: path prefix for the model(s)\n",
    "#         \"\"\"\n",
    "#         assert isinstance(path, str), f\"path must be a single path!\"\n",
    "#         if prefix is None:\n",
    "#             prefix = ''\n",
    "#         else:\n",
    "#             assert osp.isdir(prefix), f\"prefix must be a valid directory or None!\"\n",
    "#         self.session = onnxruntime.InferenceSession(osp.join(prefix, path))\n",
    "#         self.input = self.session.get_inputs()[0].shape\n",
    "\n",
    "#     def process_videos(self, filenames, confidence=0.45, codec='mp4v', progress=True, debug=False):\n",
    "#         THRESHOLD_CONFIDENCE = confidence\n",
    "#         PROGRESS = progress\n",
    "#         DEBUG = debug\n",
    "\n",
    "#         boxes_total = {}\n",
    "#         tiles_total = {}\n",
    "#         times_total = {}\n",
    "\n",
    "#         for filename_source in tqdm(filenames, position=0, leave=True, disable=True):\n",
    "#             video_source = cv.VideoCapture(filename_source)\n",
    "#             boxes_total[filename_source] = np.zeros((0, 7), dtype=np.float32)  # []\n",
    "#             tiles_total[filename_source] = []\n",
    "#             times_total[filename_source] = {\n",
    "#                 'frames': [],\n",
    "#                 'total': None\n",
    "#             }\n",
    "#             try:\n",
    "#                 if video_source.isOpened():\n",
    "#                     count = 0\n",
    "#                     count_total = int(video_source.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "#                     index_frame = -1\n",
    "#                     fps = video_source.get(cv.CAP_PROP_FPS)\n",
    "#                     w, h = video_source.get(cv.CAP_PROP_FRAME_WIDTH), video_source.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "#                     w, h = tuple(map(int, (w, h)))\n",
    "#                     filename_target = f\"{osp.splitext(filename_source)[0]}.output.mp4\"\n",
    "#                     video_target = cv.VideoWriter(filename_target, cv.VideoWriter_fourcc(*codec), fps, (w, h), True)\n",
    "#                     # boxes_video = np.zeros((0, 7), dtype=np.float32)\n",
    "#                     with tqdm(total=count_total, position=0, leave=True, disable=not PROGRESS or DEBUG) as progress_file:\n",
    "#                         while True:\n",
    "#                             time_start = perf_counter()\n",
    "#                             ok, frame = video_source.read()\n",
    "#                             index_frame += 1\n",
    "#                             if not ok:\n",
    "#                                 break\n",
    "#                             else:\n",
    "#                                 frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "#                             tiles = get_tiles(frame, self.input[-1:-3:-1])\n",
    "#                             boxes_frame = np.zeros((0, 6), dtype=np.float32)\n",
    "#                             # boxes_debug = np.zeros((0, 6), dtype=np.float32)\n",
    "#                             for i in range(tiles.shape[1]):\n",
    "#                                 for j in range(tiles.shape[0]):\n",
    "#                                     tile = tiles[j, i]\n",
    "#                                     image = cv.cvtColor(frame[tile.slice], cv.COLOR_BGR2RGB)\n",
    "#                                     # print(f\"DEBUG: image shape = {image.shape}, slice = {tile.slice}\")\n",
    "#                                     # ONNX inference\n",
    "#                                     batch = np.moveaxis(image, -1, 0)[None, ...] / np.float32(255)\n",
    "#                                     boxes = self.session.run(None, {self.session.get_inputs()[0].name: batch})[0][0]  # TODO: batch size > 1\n",
    "#                                     tile.bboxes = np.zeros((0, 6), dtype=np.float32)  # <- boxes\n",
    "#                                     if DEBUG:\n",
    "#                                         print(f\"Patch {(i, j)} {(tile.x1, tile.y1, tile.x2, tile.y2)}, boxes = {boxes.shape}\")\n",
    "#                                     # assert False\n",
    "#                                     # TODO: preprocess edge boxes\n",
    "#                                     # boxes_norm = absolute_to_relative(yolo_to_xyxy(boxes, frame[tile.slice], tile.x1, tile.y1), frame[tile.slice])\n",
    "#                                     boxes_norm = yolo_to_xyxy(boxes, frame, (1, 1), tile.x1, tile.y1)\n",
    "#                                     boxes_norm = absolute_to_relative(boxes_norm, frame)\n",
    "#                                     boxes_norm_ = boxes_norm\n",
    "#                                     # boxes_debug = np.concatenate((boxes_debug, boxes_norm))\n",
    "#                                     # assert False\n",
    "\n",
    "#                                     # NMS\n",
    "#                                     # boxes_norm = boxes_norm[None, ...]\n",
    "#                                     boxes_nms = boxes_norm[boxes_norm[..., 4] > THRESHOLD_CONFIDENCE]\n",
    "#                                     # if len(boxes_norm):\n",
    "#                                     #     boxes_nms = nms(\n",
    "#                                     #         (boxes_norm[..., :4],  # np.clip(boxes_norm[..., :4], 0, 1),\n",
    "#                                     #          boxes_norm[..., :4],\n",
    "#                                     #         ),\n",
    "#                                     #         (boxes_norm[..., 4],\n",
    "#                                     #          boxes_norm[..., 4],\n",
    "#                                     #         ),\n",
    "#                                     #         (boxes_norm[..., 5].round(),\n",
    "#                                     #          boxes_norm[..., 5].round(),\n",
    "#                                     #         ), iou_thr=0.65  # 0.175\n",
    "#                                     #     )\n",
    "#                                     #     boxes_nms = np.column_stack(boxes_nms)\n",
    "#                                     # else:\n",
    "#                                     #     boxes_nms = boxes_norm\n",
    "\n",
    "#                                     # boxes_norm = normalize_boxes(boxes_nms, image, denormalize=True)\n",
    "#                                     # boxes_norm[:, 0:4:2] += tile.x1\n",
    "#                                     # boxes_norm[:, 1:4:2] += tile.y1\n",
    "#                                     # boxes_norm = normalize_boxes(boxes_nms, image, denormalize=True)\n",
    "\n",
    "#                                     if DEBUG:\n",
    "#                                         print(f\"Boxes frame = {boxes_frame.shape}, boxes NMS = {boxes_nms.shape}\")\n",
    "#                                     # if isinstance(boxes_frame, np.ndarray):\n",
    "#                                     #     # boxes_norm = (boxes_frame, boxes_nms)\n",
    "#                                     #     boxes_norm = (boxes_frame, boxes_norm_)\n",
    "#                                     #     print(f\"Boxes frame = {boxes_frame.shape}\")\n",
    "#                                     # else:\n",
    "#                                     #     # boxes_norm = (boxes_nms, boxes_nms)\n",
    "#                                     #     boxes_norm = (boxes_norm_, boxes_norm_)\n",
    "#                                     boxes_wbf = weighted_boxes_fusion(\n",
    "#                                         (np.clip(boxes_nms[..., :4], 0, 1),\n",
    "#                                          # np.clip(boxes_nms[..., :4], 0, 1),\n",
    "#                                          np.clip(boxes_frame[..., :4], 0, 1)\n",
    "#                                         ),\n",
    "#                                         (boxes_nms[..., 4],\n",
    "#                                          # boxes_nms[..., 4],\n",
    "#                                          boxes_frame[..., 4]\n",
    "#                                         ),\n",
    "#                                         (boxes_nms[..., 5].round(),\n",
    "#                                          # boxes_nms[..., 5].round(),\n",
    "#                                          boxes_frame[..., 5].round()\n",
    "#                                         ),\n",
    "#                                         iou_thr=0.175,  # 0.175\n",
    "#                                         skip_box_thr=THRESHOLD_CONFIDENCE,\n",
    "#                                         conf_type='max'\n",
    "#                                     )\n",
    "#                                     boxes_wbf = np.column_stack(boxes_wbf)\n",
    "\n",
    "#                                     boxes_frame = np.vstack((boxes_frame, boxes_wbf))\n",
    "\n",
    "#                                     # Denormalizing\n",
    "#                                     # boxes_norm = normalize_boxes(boxes_wbf, image, denormalize=True)\n",
    "#                                     # boxes_wbf[:, 0:4:2] *= image.shape[1]\n",
    "#                                     # boxes_wbf[:, 1:4:2] *= image.shape[0]\n",
    "#                                     # boxes_nms.shape\n",
    "#                                     # break\n",
    "#                             if len(boxes_frame):\n",
    "#                                 boxes_nms = nms(\n",
    "#                                     (boxes_frame[..., :4],  # np.clip(boxes_norm[..., :4], 0, 1),\n",
    "#                                      # boxes_norm[..., :4],\n",
    "#                                     ),\n",
    "#                                     (boxes_frame[..., 4],\n",
    "#                                      # boxes_norm[..., 4],\n",
    "#                                     ),\n",
    "#                                     (boxes_frame[..., 5].round(),\n",
    "#                                      # boxes_norm[..., 5].round(),\n",
    "#                                     ), iou_thr=0.65  # 0.175\n",
    "#                                 )\n",
    "#                                 boxes_nms = np.column_stack(boxes_nms)\n",
    "#                             else:\n",
    "#                                 boxes_nms = boxes_frame\n",
    "#                             boxes_frame = relative_to_absolute(boxes_nms, frame)\n",
    "#                             boxes_frame = np.insert(boxes_frame, 0, index_frame, -1)  # prepend frame# to detection vector\n",
    "#                             boxes_total[filename_source] = np.vstack([boxes_total[filename_source], boxes_frame])\n",
    "#                             tiles_total[filename_source].append(tiles)\n",
    "#                             times_total[filename_source]['frames'].append(perf_counter() - time_start)\n",
    "\n",
    "#                             # Draw detections and save to video\n",
    "#                             frame = draw_detections(frame, boxes_frame[:, 1:])\n",
    "#                             video_target.write(cv.cvtColor(frame, cv.COLOR_RGB2BGR))\n",
    "#                             if DEBUG:\n",
    "#                                 print(f\"Frame {count:05d} done in {times_total[filename_source]['frames'][-1]:.3f} sec\")\n",
    "#                             count += 1\n",
    "#                             progress_file.update(1)\n",
    "#                             # break\n",
    "#                     video_target.release()\n",
    "#                 else:\n",
    "#                     print(f\"Can't open source file '{filename_source}'...\")\n",
    "#             finally:\n",
    "#                 try:\n",
    "#                     video_target.release()\n",
    "#                 except:\n",
    "#                     pass\n",
    "#                 video_source.release()\n",
    "#             times_total[filename_source]['frames'] = np.array(times_total[filename_source]['frames'])\n",
    "#             times_total[filename_source]['total'] = times_total[filename_source]['frames'].sum()\n",
    "#             if DEBUG or True:\n",
    "#                 print(f\"File '{filename_source}' done in {times_total[filename_source]['total'] / 60:.3f} min\")\n",
    "#             # break\n",
    "#         return boxes_total, tiles_total, times_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from projectp.inference import InferenceONNX\n",
    "\n",
    "\n",
    "inference_onnx = InferenceONNX(NAME_MODEL, prefix=PATH_MODELS)\n",
    "# boxes_total, tiles_total, times_total = inference_onnx.process_videos(sorted(glob(osp.join(PATH_DATA, '*.MOV')))[:1])\n",
    "boxes_total, tiles_total, times_total = inference_onnx.process_images(sorted(glob(osp.join(PATH_DATA, '*.jpg')))[:1])\n",
    "\n",
    "# boxes_total[filename_source][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "frame_data = pd.DataFrame()\n",
    "\n",
    "for key in boxes_total:\n",
    "    print(key, boxes_total[key].shape)\n",
    "    frame_video = pd.DataFrame(\n",
    "        boxes_total[key], columns=['frame', 'center_x', 'center_y', 'width', 'height', 'confidence', 'class']\n",
    "    )\n",
    "    frame_video['path'] = osp.realpath(osp.abspath(osp.dirname(key)))\n",
    "    frame_video['filename'] = osp.basename(key)\n",
    "    frame_data = pd.concat([frame_data, frame_video.apply(partial(pd.to_numeric, downcast='integer'), errors='ignore')])\n",
    "\n",
    "frame_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_data = frame_data.groupby(['frame'])\n",
    "\n",
    "frame_detections = group_data.count().mean(axis=1).apply(int).to_frame(name='count')\n",
    "\n",
    "frame_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_detections['step'] = frame_detections.index.to_series().diff().fillna(0).apply(int)\n",
    "\n",
    "frame_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frame_gaps = frame_detections.reset_index().diff().fillna(0)[['frame']]\n",
    "\n",
    "# frame_gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_detections[frame_detections['step'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_data[frame_data['frame'].isin((frame_detections[frame_detections['step'] > 1]).index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_detections.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_detections['count'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_detections['count'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_detections['count'].interpolate().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# reload(plt)\n",
    "# from matplotlib.pyplot import legend\n",
    "# plt.legend = legend\n",
    "\n",
    "\n",
    "# polynomic = lambda x: x * np.sin(x)\n",
    "\n",
    "x_train = frame_detections.index.to_numpy()[::5]\n",
    "x_test = frame_detections.index.to_numpy()#[2::4]\n",
    "y_train = frame_detections['count'].to_numpy()[::5]\n",
    "\n",
    "X_train = x_train[..., None]\n",
    "X_test = x_test[..., None]\n",
    "Y_train = y_train[..., None]\n",
    "\n",
    "\n",
    "alpha = 1e-3\n",
    "degree = 7\n",
    "model_poly = make_pipeline(PolynomialFeatures(degree), Ridge(alpha=alpha))\n",
    "model_spline = make_pipeline(SplineTransformer(n_knots=4, degree=degree), Ridge(alpha=alpha))\n",
    "model_ridge = make_pipeline(Ridge(alpha=alpha))\n",
    "\n",
    "model_poly.fit(X_train, y_train)\n",
    "model_spline.fit(X_train, y_train)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "y_poly = model_poly.predict(X_test)\n",
    "y_spline = model_spline.predict(X_test)\n",
    "y_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "plt.plot(frame_detections['count'])\n",
    "plt.plot(y_poly)\n",
    "plt.plot(y_spline)\n",
    "plt.plot(y_ridge)\n",
    "plt.plot([frame_detections['count'].quantile(0.95)] * len(frame_detections['count']))\n",
    "plt.legend(['detections', f'polynomial-{degree}', f'spline-{degree}', 'ridge', '95-percentile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalize = lambda grp: (grp - grp.mean()) / grp.var()\n",
    "\n",
    "group_data['confidence'].transform(normalize).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_data.pivot_table(index='frame', columns=['class'], values=['confidence'], aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_data.stack().to_frame().unstack(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_data.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group_data[['width', 'height']].mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frame_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frame_detections['count'][None, ...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frame_detections['count'][..., None].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# frame_video.apply(pd.to_numeric, errors='ignore')values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.save('boxes-total.npy', boxes_total, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ok = np.random.rand(*(2, 4, 3))\n",
    "\n",
    "ok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ok.shape[1::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ok_ = np.random.rand(*(2, 4, 3))\n",
    "\n",
    "ok_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.concatenate([ok[None, ...], ok_[None, ...]]).mean(0)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(np.concatenate([ok[None, ...], ok_[None, ...]]).T @ np.array([1.0, 0.0])).T#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# boxes_norm = absolute_to_relative(boxes_total[0], frame)\n",
    "# boxes_nms = nms(\n",
    "#     (boxes_norm[..., :4],  # np.clip(boxes_norm[..., :4], 0, 1),\n",
    "#      # boxes_norm[..., :4],\n",
    "#     ),\n",
    "#     (boxes_norm[..., 4],\n",
    "#      # boxes_norm[..., 4],\n",
    "#     ),\n",
    "#     (boxes_norm[..., 5].round(),\n",
    "#      # boxes_norm[..., 5].round(),\n",
    "#     ), iou_thr=0.65  # 0.175\n",
    "# )\n",
    "# boxes_nms = np.column_stack(boxes_nms)\n",
    "# boxes_nms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist((boxes[:, 4:5]), bins=100, log=True, range=(0, 0.004))\n",
    "# plt.hist(boxes[:, 5:6], bins=100, log=False, range=(0.99999, 1))\n",
    "plt.legend(['conf', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# plt.scatter(boxes[:, 0], boxes[:, 1], c='red')\n",
    "# plt.scatter(boxes[:, 2], boxes[:, 3], c='green')\n",
    "plt.scatter(boxes_norm_[:, 0], boxes_norm_[:, 1], c='yellow')\n",
    "plt.scatter(boxes_norm_[:, 2], boxes_norm_[:, 3], c='blue')\n",
    "# plt.scatter(boxes_wbf[:, 0], boxes_wbf[:, 1], c='red')\n",
    "# plt.scatter(boxes_wbf[:, 2], boxes_wbf[:, 3], c='green')\n",
    "plt.scatter(boxes_nms[:, 0], boxes_nms[:, 1], c='red')\n",
    "plt.scatter(boxes_nms[:, 2], boxes_nms[:, 3], c='green')\n",
    "plt.legend(['xy', 'wh', 'xy', 'wh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (tiles_total[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tiles_total[0][0, 0].bboxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "boxes_nms_absolute = relative_to_absolute(boxes_nms, frame)\n",
    "\n",
    "plt.scatter(boxes_total[filename_source][0][:, 0], boxes_total[filename_source][0][:, 1], c='red')\n",
    "plt.scatter(boxes_total[filename_source][0][:, 2], boxes_total[filename_source][0][:, 3], c='green')\n",
    "plt.scatter(boxes_nms_absolute[:, 0], boxes_nms_absolute[:, 1], c='yellow')\n",
    "plt.scatter(boxes_nms_absolute[:, 2], boxes_nms_absolute[:, 3], c='blue')\n",
    "plt.legend(['xy1', 'xy2', 'xy1', 'xy2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0, 1, 2, 3 = x1, y1, x2, y2\n",
    "# x2 < x1 -> 2 < 0\n",
    "# y2 < y1 -> 3 < 1\n",
    "\n",
    "# (boxes_total[filename_source][0][:, 3] < boxes_total[filename_source][0][:, 1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detections = boxes_total[next(iter(boxes_total.keys()))]\n",
    "\n",
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detections[np.where(detections[:, 0] == 351)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detections_counts = detections[:, 0]\n",
    "\n",
    "detections_counts, detections_index = np.histogram(detections_counts, bins=detections_counts.max().astype(int) + 1)\n",
    "\n",
    "detections_index[detections_counts.argmax()], detections_counts.max(), np.percentile(detections_counts, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detections[np.where(detections[:, 0] == 1677)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detections_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detections_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detections_index[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.scatter(*np.histogram(detections_counts, bins=detections_counts.max().astype(int) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(detections_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.hist(detections[:, 0], bins=detections[:, 0].max().astype(int) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm, colors\n",
    "\n",
    "\n",
    "detections = boxes_nms_absolute\n",
    "\n",
    "# cmap = plt.get_cmap('gist_rainbow')\n",
    "# cnorm = colors.Normalize(0, len(detections))\n",
    "\n",
    "# scma = cm.ScalarMappable(norm=cnorm, cmap=cmap)\n",
    "\n",
    "# scma.to_rgba(len(detections) - 1)\n",
    "\n",
    "plt.clf()\n",
    "figure, axes = plt.subplots(figsize=(frame.shape[1] / 72 / 1, frame.shape[0] / 72 / 1), dpi=72)\n",
    "# axes.imshow(frame[tile.slice])\n",
    "frame_dots = frame.copy()\n",
    "# for i, detection in enumerate(detections):  # boxes_total[filename_source][0]:\n",
    "#     coords = detection[0:2] + (detection[2:4] - detection[0:2]) / 2\n",
    "#     frame_dots = cv.circle(frame_dots, (coords.round().astype('int')), radius=2,\n",
    "#                            color=(np.array(scma.to_rgba(i)[:3]) * 255).round().astype('uint8').tolist(),\n",
    "#                            thickness=2)\n",
    "# text = f\"Detected: {len(detections)}\"\n",
    "# font_face = cv.FONT_HERSHEY_COMPLEX_SMALL\n",
    "# font_scale = 2\n",
    "# font_thickness = 3\n",
    "# # text_baseline = 0\n",
    "# text_size = cv.getTextSize(text, font_face, font_scale, font_thickness)\n",
    "# # text_baseline += font_thickness\n",
    "# # text_origin = frame_dots.shape[1] - text_size[0][0] / 2, frame_dots.shape[0] - text_size[0][1] / 2\n",
    "# text_origin = 32, text_size[0][1] * 1.5\n",
    "\n",
    "# cv.putText(frame_dots, text, tuple(map(lambda x: round(x + 1), text_origin)),\n",
    "#            font_face, font_scale, (0, 0, 0), font_thickness, 8)\n",
    "# cv.putText(frame_dots, text, tuple(map(lambda x: round(x), text_origin)),\n",
    "#            font_face, font_scale, (255, 255, 255), font_thickness, 8)\n",
    "\n",
    "draw_detections(frame_dots, detections)\n",
    "cv.imwrite('frame.png', cv.cvtColor(frame_dots, cv.COLOR_RGB2BGR))\n",
    "\n",
    "axes.imshow(frame_dots)\n",
    "# for i, detection in enumerate(detections):  # boxes_total[filename_source][0]:\n",
    "# # for bbox in boxes_nms:\n",
    "#     bbox = detection[:4]\n",
    "#     axes.add_patch(patches.Rectangle(bbox[:2], *(bbox[2:4] - bbox[:2]), linewidth=1,\n",
    "#     # axes.add_patch(patches.Rectangle(bbox[:2], *(bbox[2:4] - 0), linewidth=2,\n",
    "#                                      edgecolor=scma.to_rgba(i),  # 'pink',\n",
    "#                                      facecolor='none'))\n",
    "#     axes.legend([f\"adult ({len(detections)})\"])\n",
    "#     # break\n",
    "plt.axis('off')\n",
    "# plt.savefig('frame.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "timestamp\n",
    "\n",
    "# !7z a -tzip -mx=9 ../results-{timestamp}.zip *\n",
    "!echo {timestamp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf projectp.zip\n",
    "!7z a -bso0 -bsp0 -tzip projectp.zip projectp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# from typing import Iterable, List, Sequence, Tuple\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def compute_pyramid_patch_weight_loss(width: int, height: int) -> np.ndarray:\n",
    "#     \"\"\"Compute a weight matrix that assigns bigger weight on pixels in center and\n",
    "#     less weight to pixels on image boundary.\n",
    "#     This weight matrix then used for merging individual tile predictions and helps dealing\n",
    "#     with prediction artifacts on tile boundaries.\n",
    "#     :param width: Tile width\n",
    "#     :param height: Tile height\n",
    "#     :return: Since-channel image [Width x Height]\n",
    "#     \"\"\"\n",
    "#     xc = width * 0.5\n",
    "#     yc = height * 0.5\n",
    "#     xl = 0\n",
    "#     xr = width\n",
    "#     yb = 0\n",
    "#     yt = height\n",
    "#     Dc = np.zeros((width, height))\n",
    "#     De = np.zeros((width, height))\n",
    "\n",
    "#     Dcx = np.square(np.arange(width) - xc + 0.5)\n",
    "#     Dcy = np.square(np.arange(height) - yc + 0.5)\n",
    "#     Dc = np.sqrt(Dcx[np.newaxis].transpose() + Dcy)\n",
    "\n",
    "#     De_l = np.square(np.arange(width) - xl + 0.5) + np.square(0.5)\n",
    "#     De_r = np.square(np.arange(width) - xr + 0.5) + np.square(0.5)\n",
    "#     De_b = np.square(0.5) + np.square(np.arange(height) - yb + 0.5)\n",
    "#     De_t = np.square(0.5) + np.square(np.arange(height) - yt + 0.5)\n",
    "\n",
    "#     De_x = np.sqrt(np.minimum(De_l, De_r))\n",
    "#     De_y = np.sqrt(np.minimum(De_b, De_t))\n",
    "#     De = np.minimum(De_x[np.newaxis].transpose(), De_y)\n",
    "\n",
    "#     alpha = (width * height) / np.sum(np.divide(De, np.add(Dc, De)))\n",
    "#     W = alpha * np.divide(De, np.add(Dc, De))\n",
    "#     return W, Dc, De\n",
    "\n",
    "\n",
    "# class ImageSlicer:\n",
    "#     tile_size: Tuple[int, int]\n",
    "#     tile_step: Tuple[int, int]\n",
    "#     overlap: Tuple[int, int]\n",
    "\n",
    "#     \"\"\"\n",
    "#     Helper class to slice image into tiles and merge them back. NO BBOXES, MAY WORK WITH MASKS\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, image_shape: Tuple[int, int], tile_size, tile_step=0, image_margin=0,\n",
    "#                  weight=\"mean\"):\n",
    "#         \"\"\"\n",
    "#         :param image_shape: Shape of the source image (H, W)\n",
    "#         :param tile_size: Tile size (Scalar or tuple (H, W))\n",
    "#         :param tile_step: Step in pixels between tiles (Scalar or tuple (H, W))\n",
    "#         :param image_margin:\n",
    "#         :param weight: Fusion algorithm. 'mean' - avergaing\n",
    "#         \"\"\"\n",
    "#         self.image_height = image_shape[0]\n",
    "#         self.image_width = image_shape[1]\n",
    "\n",
    "#         if isinstance(tile_size, (np.ndarray, Sequence)):\n",
    "#             if len(tile_size) != 2:\n",
    "#                 raise ValueError(f\"Tile size must have exactly 2 elements. Got: tile_size={tile_size}\")\n",
    "#             self.tile_size = int(tile_size[0]), int(tile_size[1])\n",
    "#         else:\n",
    "#             self.tile_size = int(tile_size), int(tile_size)\n",
    "\n",
    "#         if isinstance(tile_step, (np.ndarray, Sequence)):\n",
    "#             if len(tile_step) != 2:\n",
    "#                 raise ValueError(f\"Tile size must have exactly 2 elements. Got: tile_step={tile_size}\")\n",
    "#             self.tile_step = int(tile_step[0]), int(tile_step[1])\n",
    "#         else:\n",
    "#             self.tile_step = int(tile_step), int(tile_step)\n",
    "\n",
    "#         weights = {\"mean\": self._mean, \"pyramid\": self._pyramid}\n",
    "\n",
    "#         self.weight = weight if isinstance(weight, np.ndarray) else weights[weight](self.tile_size)\n",
    "\n",
    "#         if self.tile_step[0] < 1 or self.tile_step[0] > self.tile_size[0]:\n",
    "#             raise ValueError()\n",
    "#         if self.tile_step[1] < 1 or self.tile_step[1] > self.tile_size[1]:\n",
    "#             raise ValueError()\n",
    "\n",
    "#         overlap = (self.tile_size[0] - self.tile_step[0], self.tile_size[1] - self.tile_step[1])\n",
    "\n",
    "#         self.margin_left = 0\n",
    "#         self.margin_right = 0\n",
    "#         self.margin_top = 0\n",
    "#         self.margin_bottom = 0\n",
    "\n",
    "#         if image_margin == 0:\n",
    "#             # In case margin is not set, we compute it manually\n",
    "\n",
    "#             nw = max(1, math.ceil((self.image_width - overlap[1]) / self.tile_step[1]))\n",
    "#             nh = max(1, math.ceil((self.image_height - overlap[0]) / self.tile_step[0]))\n",
    "\n",
    "#             extra_w = self.tile_step[1] * nw - (self.image_width - overlap[1])\n",
    "#             extra_h = self.tile_step[0] * nh - (self.image_height - overlap[0])\n",
    "\n",
    "#             self.margin_left = extra_w // 2\n",
    "#             self.margin_right = extra_w - self.margin_left\n",
    "#             self.margin_top = extra_h // 2\n",
    "#             self.margin_bottom = extra_h - self.margin_top\n",
    "\n",
    "#         else:\n",
    "#             if isinstance(image_margin, Sequence):\n",
    "#                 margin_left, margin_right, margin_top, margin_bottom = image_margin\n",
    "#             else:\n",
    "#                 margin_left = margin_right = margin_top = margin_bottom = image_margin\n",
    "\n",
    "#             self.margin_left = margin_left\n",
    "#             self.margin_right = margin_right\n",
    "#             self.margin_top = margin_top\n",
    "#             self.margin_bottom = margin_bottom\n",
    "\n",
    "#         crops = []\n",
    "#         bbox_crops = []\n",
    "\n",
    "#         for y in range(\n",
    "#             0, self.image_height + self.margin_top + self.margin_bottom - self.tile_size[0] + 1,\n",
    "#             self.tile_step[0]\n",
    "#         ):\n",
    "#             for x in range(\n",
    "#                 0, self.image_width + self.margin_left + self.margin_right - self.tile_size[1] + 1,\n",
    "#                 self.tile_step[1]\n",
    "#             ):\n",
    "#                 crops.append((x, y, self.tile_size[1], self.tile_size[0]))\n",
    "#                 bbox_crops.append((x - self.margin_left, y - self.margin_top, self.tile_size[1],\n",
    "#                                    self.tile_size[0]))\n",
    "\n",
    "#         self.crops = np.array(crops)\n",
    "#         self.bbox_crops = np.array(bbox_crops)\n",
    "\n",
    "#     def iter_split(\n",
    "#         self, image: np.ndarray, border_type=cv.BORDER_CONSTANT, value=0\n",
    "#     ) -> Iterable[Tuple[np.ndarray, Tuple[int, int, int, int]]]:\n",
    "#         if (image.shape[0] != self.image_height) or (image.shape[1] != self.image_width):\n",
    "#             raise ValueError()\n",
    "\n",
    "#         orig_shape_len = len(image.shape)\n",
    "\n",
    "#         for coords, crop_coords in zip(self.crops, self.bbox_crops):\n",
    "#             x, y, tile_width, tile_height = crop_coords\n",
    "#             x1 = max(x, 0)\n",
    "#             y1 = max(y, 0)\n",
    "#             x2 = min(image.shape[1], x + tile_width)\n",
    "#             y2 = min(image.shape[0], y + tile_height)\n",
    "\n",
    "#             tile = image[y1:y2, x1:x2]  # .copy()\n",
    "#             if x < 0 or y < 0 or (x + tile_width) > image.shape[1] or (y + tile_height) > image.shape[0]:\n",
    "#                 tile = cv.copyMakeBorder(\n",
    "#                     tile,\n",
    "#                     top=max(0, -y),\n",
    "#                     bottom=max(0, y + tile_height - image.shape[0]),\n",
    "#                     left=max(0, -x),\n",
    "#                     right=max(0, x + tile_width - image.shape[1]),\n",
    "#                     borderType=border_type,\n",
    "#                     value=value,\n",
    "#                 )\n",
    "\n",
    "#                 # This check recovers possible lack of last dummy dimension for single-channel images\n",
    "#                 if len(tile.shape) != orig_shape_len:\n",
    "#                     tile = np.expand_dims(tile, axis=-1)\n",
    "\n",
    "#             yield tile, coords\n",
    "\n",
    "#     def split(self, image, border_type=cv.BORDER_CONSTANT, value=0):\n",
    "#         assert image.shape[0] == self.image_height\n",
    "#         assert image.shape[1] == self.image_width\n",
    "\n",
    "#         orig_shape_len = len(image.shape)\n",
    "#         image = cv.copyMakeBorder(\n",
    "#             image,\n",
    "#             self.margin_top,\n",
    "#             self.margin_bottom,\n",
    "#             self.margin_left,\n",
    "#             self.margin_right,\n",
    "#             borderType=border_type,\n",
    "#             value=value,\n",
    "#         )\n",
    "\n",
    "#         # This check recovers possible lack of last dummy dimension for single-channel images\n",
    "#         if len(image.shape) != orig_shape_len:\n",
    "#             image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "#         tiles = []\n",
    "#         for x, y, tile_width, tile_height in self.crops:\n",
    "#             tile = image[y : y + tile_height, x : x + tile_width]  # .copy()\n",
    "#             assert tile.shape[0] == self.tile_size[0]\n",
    "#             assert tile.shape[1] == self.tile_size[1]\n",
    "\n",
    "#             tiles.append(tile)\n",
    "\n",
    "#         return tiles\n",
    "\n",
    "#     def cut_patch(self, image: np.ndarray, slice_index, border_type=cv.BORDER_CONSTANT, value=0):\n",
    "#         assert image.shape[0] == self.image_height\n",
    "#         assert image.shape[1] == self.image_width\n",
    "\n",
    "#         orig_shape_len = len(image.shape)\n",
    "#         x, y, tile_width, tile_height = self.bbox_crops[slice_index]\n",
    "\n",
    "#         x1 = max(x, 0)\n",
    "#         y1 = max(y, 0)\n",
    "#         x2 = min(image.shape[1], x + tile_width)\n",
    "#         y2 = min(image.shape[0], y + tile_height)\n",
    "\n",
    "#         tile = image[y1:y2, x1:x2]\n",
    "#         if x < 0 or y < 0 or (x + tile_width) > image.shape[1] or (y + tile_height) > image.shape[0]:\n",
    "#             tile = cv.copyMakeBorder(\n",
    "#                 tile,\n",
    "#                 top=max(0, -y),\n",
    "#                 bottom=max(0, y + tile_height - image.shape[0]),\n",
    "#                 left=max(0, -x),\n",
    "#                 right=max(0, x + tile_width - image.shape[1]),\n",
    "#                 borderType=border_type,\n",
    "#                 value=value,\n",
    "#             )\n",
    "\n",
    "#             # This check recovers possible lack of last dummy dimension for single-channel images\n",
    "#             if len(tile.shape) != orig_shape_len:\n",
    "#                 tile = np.expand_dims(tile, axis=-1)\n",
    "\n",
    "#         return tile\n",
    "\n",
    "#     @property\n",
    "#     def target_shape(self):\n",
    "#         target_shape = (\n",
    "#             self.image_height + self.margin_bottom + self.margin_top,\n",
    "#             self.image_width + self.margin_right + self.margin_left,\n",
    "#         )\n",
    "#         return target_shape\n",
    "\n",
    "#     def merge(self, tiles: List[np.ndarray], dtype=np.float32):\n",
    "#         if len(tiles) != len(self.crops):\n",
    "#             raise ValueError\n",
    "\n",
    "#         channels = 1 if len(tiles[0].shape) == 2 else tiles[0].shape[2]\n",
    "#         target_shape = (\n",
    "#             self.image_height + self.margin_bottom + self.margin_top,\n",
    "#             self.image_width + self.margin_right + self.margin_left,\n",
    "#             channels,\n",
    "#         )\n",
    "\n",
    "#         image = np.zeros(target_shape, dtype=np.float64)\n",
    "#         norm_mask = np.zeros(target_shape, dtype=np.float64)\n",
    "\n",
    "#         w = np.dstack([self.weight] * channels)\n",
    "\n",
    "#         for tile, (x, y, tile_width, tile_height) in zip(tiles, self.crops):\n",
    "#             # print(x, y, tile_width, tile_height, image.shape)\n",
    "#             image[y : y + tile_height, x : x + tile_width] += tile * w\n",
    "#             norm_mask[y : y + tile_height, x : x + tile_width] += w\n",
    "\n",
    "#         # print(norm_mask.min(), norm_mask.max())\n",
    "#         norm_mask = np.clip(norm_mask, a_min=np.finfo(norm_mask.dtype).eps, a_max=None)\n",
    "#         normalized = np.divide(image, norm_mask).astype(dtype)\n",
    "#         crop = self.crop_to_orignal_size(normalized)\n",
    "#         return crop\n",
    "\n",
    "#     def crop_to_orignal_size(self, image):\n",
    "#         assert image.shape[0] == self.target_shape[0]\n",
    "#         assert image.shape[1] == self.target_shape[1]\n",
    "#         crop = image[\n",
    "#             self.margin_top : self.image_height + self.margin_top,\n",
    "#             self.margin_left : self.image_width + self.margin_left,\n",
    "#         ]\n",
    "#         assert crop.shape[0] == self.image_height\n",
    "#         assert crop.shape[1] == self.image_width\n",
    "#         return crop\n",
    "\n",
    "#     def _mean(self, tile_size):\n",
    "#         return np.ones((tile_size[0], tile_size[1]), dtype=np.float32)\n",
    "\n",
    "#     def _pyramid(self, tile_size):\n",
    "#         w, _, _ = compute_pyramid_patch_weight_loss(tile_size[0], tile_size[1])\n",
    "#         return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math as m\n",
    "\n",
    "\n",
    "# def get_tile_step(image_shape, tile_size):\n",
    "#     height, width = image_shape[:2]\n",
    "#     num_patches_x = m.ceil(width / tile_size)\n",
    "#     num_patches_y = m.ceil(height / tile_size)\n",
    "#     shifts_x = None\n",
    "#     shifts_y = None\n",
    "#     print(f\"Size = {(width, height)}, num patches = {(num_patches_x, num_patches_y)}\")\n",
    "#     offset_x = 0\n",
    "#     for i in range(num_patches_x):\n",
    "#         offset_y = 0\n",
    "#         for j in range(num_patches_y):\n",
    "#             # print(f\"Patch {(i, j)} {(offset_x, offset_y, offset_x + tile_size, offset_y + tile_size)}\")\n",
    "#             # Update y-offset (end of iteration)\n",
    "#             shift_y = ((num_patches_y - j) - (height - offset_y) / tile_size) / (num_patches_y - j - 1 + 1e-15)\n",
    "#             shifts_y = shifts_y or shift_y\n",
    "#             offset_y += round(tile_size - tile_size * shift_y)\n",
    "#             pass\n",
    "#         # Update x-offset (end of iteration)\n",
    "#         shift_x = ((num_patches_x - i) - (width - offset_x) / tile_size) / (num_patches_x - i - 1 + 1e-15)\n",
    "#         shifts_x = shifts_x or shift_x\n",
    "#         offset_x += round(tile_size - tile_size * shift_x)\n",
    "#         # print(shifts_x, shifts_y)\n",
    "#     return tile_size - tile_size * shifts_y, tile_size - tile_size * shifts_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes = []\n",
    "\n",
    "# for filename in glob(osp.join(PATH_DATA, '*')):\n",
    "#     video = cv.VideoCapture(filename)\n",
    "#     if video.isOpened():\n",
    "#         height, width = video.get(cv.CAP_PROP_FRAME_HEIGHT), video.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "#         step_y, step_x = get_tile_step((height, width), SIZE)\n",
    "#         print(f\"Tile steps = {step_y, step_x}\")\n",
    "#         while True:\n",
    "#             ok, frame = video.read()\n",
    "#             if not ok:\n",
    "#                 break\n",
    "#             # slices = ImageSlicer(image_shape=frame.shape[:2], tile_size=SIZE, tile_step=(step_y, step_x))\n",
    "#             # slices.split(frame)\n",
    "#             # for image, coordinates in slices.iter_split(frame):\n",
    "#             #     print(f\"Tile coordinates = {coordinates}\")\n",
    "#             image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "#             batch = np.moveaxis(image, -1, 0)[None, ...] / np.float32(255)\n",
    "#             boxes += session.run(None, {session.get_inputs()[0].name: batch})[0][0]\n",
    "#             break\n",
    "#     video.release()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do This V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prefilter_boxes(boxes, scores, labels, weights, thr):\n",
    "#     # Create dict with boxes stored by its label\n",
    "#     new_boxes = dict()\n",
    "\n",
    "#     for t in range(len(boxes)):\n",
    "\n",
    "#         if len(boxes[t]) != len(scores[t]):\n",
    "#             print('Error. Length of boxes arrays not equal to length of scores array: {} != {}'.format(len(boxes[t]), len(scores[t])))\n",
    "#             exit()\n",
    "\n",
    "#         if len(boxes[t]) != len(labels[t]):\n",
    "#             print('Error. Length of boxes arrays not equal to length of labels array: {} != {}'.format(len(boxes[t]), len(labels[t])))\n",
    "#             exit()\n",
    "\n",
    "#         for j in range(len(boxes[t])):\n",
    "#             score = scores[t][j]\n",
    "#             if score < thr:\n",
    "#                 continue\n",
    "#             label = int(labels[t][j])\n",
    "#             box_part = boxes[t][j]\n",
    "#             x1 = float(box_part[0])\n",
    "#             y1 = float(box_part[1])\n",
    "#             x2 = float(box_part[2])\n",
    "#             y2 = float(box_part[3])\n",
    "\n",
    "#             # Box data checks\n",
    "#             if x2 < x1:\n",
    "#                 warnings.warn('X2 < X1 value in box. Swap them.')\n",
    "#                 x1, x2 = x2, x1\n",
    "#             if y2 < y1:\n",
    "#                 warnings.warn('Y2 < Y1 value in box. Swap them.')\n",
    "#                 y1, y2 = y2, y1\n",
    "#             if x1 < 0:\n",
    "#                 warnings.warn('X1 < 0 in box. Set it to 0.')\n",
    "#                 x1 = 0\n",
    "#             if x1 > 1:\n",
    "#                 warnings.warn('X1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "#                 x1 = 1\n",
    "#             if x2 < 0:\n",
    "#                 warnings.warn('X2 < 0 in box. Set it to 0.')\n",
    "#                 x2 = 0\n",
    "#             if x2 > 1:\n",
    "#                 warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "#                 x2 = 1\n",
    "#             if y1 < 0:\n",
    "#                 warnings.warn('Y1 < 0 in box. Set it to 0.')\n",
    "#                 y1 = 0\n",
    "#             if y1 > 1:\n",
    "#                 warnings.warn('Y1 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "#                 y1 = 1\n",
    "#             if y2 < 0:\n",
    "#                 warnings.warn('Y2 < 0 in box. Set it to 0.')\n",
    "#                 y2 = 0\n",
    "#             if y2 > 1:\n",
    "#                 warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
    "#                 y2 = 1\n",
    "#             if (x2 - x1) * (y2 - y1) == 0.0:\n",
    "#                 warnings.warn(\"Zero area box skipped: {}.\".format(box_part))\n",
    "#                 continue\n",
    "\n",
    "#             # [label, score, weight, model index, x1, y1, x2, y2]\n",
    "#             b = [int(label), float(score) * weights[t], weights[t], t, x1, y1, x2, y2]\n",
    "#             if label not in new_boxes:\n",
    "#                 new_boxes[label] = []\n",
    "#             new_boxes[label].append(b)\n",
    "\n",
    "#     # Sort each list in dict by score and transform it to numpy array\n",
    "#     for k in new_boxes:\n",
    "#         current_boxes = np.array(new_boxes[k])\n",
    "#         new_boxes[k] = current_boxes[current_boxes[:, 1].argsort()[::-1]]\n",
    "\n",
    "#     return new_boxes\n",
    "\n",
    "\n",
    "# def get_weighted_box(boxes, conf_type='avg'):\n",
    "#     \"\"\"\n",
    "#     Create weighted box for set of boxes\n",
    "#     :param boxes: set of boxes to fuse\n",
    "#     :param conf_type: type of confidence one of 'avg' or 'max'\n",
    "#     :return: weighted box (label, score, weight, model index, x1, y1, x2, y2)\n",
    "#     \"\"\"\n",
    "\n",
    "#     box = np.zeros(8, dtype=np.float32)\n",
    "#     conf = 0\n",
    "#     conf_list = []\n",
    "#     w = 0\n",
    "#     for b in boxes:\n",
    "#         box[4:] += (b[1] * b[4:])\n",
    "#         conf += b[1]\n",
    "#         conf_list.append(b[1])\n",
    "#         w += b[2]\n",
    "#     box[0] = boxes[0][0]\n",
    "#     if conf_type in ('avg', 'box_and_model_avg', 'absent_model_aware_avg'):\n",
    "#         box[1] = conf / len(boxes)\n",
    "#     elif conf_type == 'max':\n",
    "#         box[1] = np.array(conf_list).max()\n",
    "#     box[2] = w\n",
    "#     box[3] = -1 # model index field is retained for consistency but is not used.\n",
    "#     box[4:] /= conf\n",
    "#     return box\n",
    "\n",
    "\n",
    "# def find_matching_box_fast(boxes_list, new_box, match_iou):\n",
    "#     \"\"\"\n",
    "#         Reimplementation of find_matching_box with numpy instead of loops. Gives significant speed up for larger arrays\n",
    "#         (~100x). This was previously the bottleneck since the function is called for every entry in the array.\n",
    "#     \"\"\"\n",
    "#     def bb_iou_array(boxes, new_box):\n",
    "#         # bb interesection over union\n",
    "#         xA = np.maximum(boxes[:, 0], new_box[0])\n",
    "#         yA = np.maximum(boxes[:, 1], new_box[1])\n",
    "#         xB = np.minimum(boxes[:, 2], new_box[2])\n",
    "#         yB = np.minimum(boxes[:, 3], new_box[3])\n",
    "\n",
    "#         interArea = np.maximum(xB - xA, 0) * np.maximum(yB - yA, 0)\n",
    "\n",
    "#         # compute the area of both the prediction and ground-truth rectangles\n",
    "#         boxAArea = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "#         boxBArea = (new_box[2] - new_box[0]) * (new_box[3] - new_box[1])\n",
    "\n",
    "#         iou = interArea / (boxAArea + boxBArea - interArea)\n",
    "\n",
    "#         return iou\n",
    "\n",
    "#     if boxes_list.shape[0] == 0:\n",
    "#         return -1, match_iou\n",
    "\n",
    "#     # boxes = np.array(boxes_list)\n",
    "#     boxes = boxes_list\n",
    "\n",
    "#     ious = bb_iou_array(boxes[:, 4:], new_box[4:])\n",
    "\n",
    "#     ious[boxes[:, 0] != new_box[0]] = -1\n",
    "\n",
    "#     best_idx = np.argmax(ious)\n",
    "#     best_iou = ious[best_idx]\n",
    "\n",
    "#     if best_iou <= match_iou:\n",
    "#         best_iou = match_iou\n",
    "#         best_idx = -1\n",
    "\n",
    "#     return best_idx, best_iou\n",
    "\n",
    "\n",
    "# def weighted_boxes_fusion(\n",
    "#         boxes_list,\n",
    "#         scores_list,\n",
    "#         labels_list,\n",
    "#         weights=None,\n",
    "#         iou_thr=0.55,\n",
    "#         skip_box_thr=0.0,\n",
    "#         conf_type='avg',\n",
    "#         allows_overflow=False\n",
    "# ):\n",
    "#     '''\n",
    "#     :param boxes_list: list of boxes predictions from each model, each box is 4 numbers.\n",
    "#     It has 3 dimensions (models_number, model_preds, 4)\n",
    "#     Order of boxes: x1, y1, x2, y2. We expect float normalized coordinates [0; 1]\n",
    "#     :param scores_list: list of scores for each model\n",
    "#     :param labels_list: list of labels for each model\n",
    "#     :param weights: list of weights for each model. Default: None, which means weight == 1 for each model\n",
    "#     :param iou_thr: IoU value for boxes to be a match\n",
    "#     :param skip_box_thr: exclude boxes with score lower than this variable\n",
    "#     :param conf_type: how to calculate confidence in weighted boxes.\n",
    "#         'avg': average value,\n",
    "#         'max': maximum value,\n",
    "#         'box_and_model_avg': box and model wise hybrid weighted average,\n",
    "#         'absent_model_aware_avg': weighted average that takes into account the absent model.\n",
    "#     :param allows_overflow: false if we want confidence score not exceed 1.0\n",
    "#     :return: boxes: boxes coordinates (Order of boxes: x1, y1, x2, y2).\n",
    "#     :return: scores: confidence scores\n",
    "#     :return: labels: boxes labels\n",
    "#     '''\n",
    "\n",
    "#     if weights is None:\n",
    "#         weights = np.ones(len(boxes_list))\n",
    "#     if len(weights) != len(boxes_list):\n",
    "#         print('Warning: incorrect number of weights {}. Must be: {}. Set weights equal to 1.'.format(len(weights), len(boxes_list)))\n",
    "#         weights = np.ones(len(boxes_list))\n",
    "#     weights = np.array(weights)\n",
    "\n",
    "#     if conf_type not in ['avg', 'max', 'box_and_model_avg', 'absent_model_aware_avg']:\n",
    "#         print('Unknown conf_type: {}. Must be \"avg\", \"max\" or \"box_and_model_avg\", or \"absent_model_aware_avg\"'.format(conf_type))\n",
    "#         exit()\n",
    "\n",
    "#     filtered_boxes = prefilter_boxes(boxes_list, scores_list, labels_list, weights, skip_box_thr)\n",
    "#     if len(filtered_boxes) == 0:\n",
    "#         return np.zeros((0, 4)), np.zeros((0,)), np.zeros((0,))\n",
    "\n",
    "#     overall_boxes = []\n",
    "#     for label in filtered_boxes:\n",
    "#         boxes = filtered_boxes[label]\n",
    "#         new_boxes = []\n",
    "#         weighted_boxes = np.empty((0, 8))\n",
    "\n",
    "#         # Clusterize boxes\n",
    "#         for j in range(0, len(boxes)):\n",
    "#             index, best_iou = find_matching_box_fast(weighted_boxes, boxes[j], iou_thr)\n",
    "\n",
    "#             if index != -1:\n",
    "#                 new_boxes[index].append(boxes[j])\n",
    "#                 weighted_boxes[index] = get_weighted_box(new_boxes[index], conf_type)\n",
    "#             else:\n",
    "#                 new_boxes.append([boxes[j].copy()])\n",
    "#                 weighted_boxes = np.vstack((weighted_boxes, boxes[j].copy()))\n",
    "\n",
    "#         # Rescale confidence based on number of models and boxes\n",
    "#         for i in range(len(new_boxes)):\n",
    "#             clustered_boxes = new_boxes[i]\n",
    "#             if conf_type == 'box_and_model_avg':\n",
    "#                 clustered_boxes = np.array(clustered_boxes)\n",
    "#                 # weighted average for boxes\n",
    "#                 weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / weighted_boxes[i, 2]\n",
    "#                 # identify unique model index by model index column\n",
    "#                 _, idx = np.unique(clustered_boxes[:, 3], return_index=True)\n",
    "#                 # rescale by unique model weights\n",
    "#                 weighted_boxes[i, 1] = weighted_boxes[i, 1] *  clustered_boxes[idx, 2].sum() / weights.sum()\n",
    "#             elif conf_type == 'absent_model_aware_avg':\n",
    "#                 clustered_boxes = np.array(clustered_boxes)\n",
    "#                 # get unique model index in the cluster\n",
    "#                 models = np.unique(clustered_boxes[:, 3]).astype(int)\n",
    "#                 # create a mask to get unused model weights\n",
    "#                 mask = np.ones(len(weights), dtype=bool)\n",
    "#                 mask[models] = False\n",
    "#                 # absent model aware weighted average\n",
    "#                 weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / (weighted_boxes[i, 2] + weights[mask].sum())\n",
    "#             elif conf_type == 'max':\n",
    "#                 weighted_boxes[i, 1] = weighted_boxes[i, 1] / weights.max()\n",
    "#             elif not allows_overflow:\n",
    "#                 weighted_boxes[i, 1] = weighted_boxes[i, 1] * min(len(weights), len(clustered_boxes)) / weights.sum()\n",
    "#             else:\n",
    "#                 weighted_boxes[i, 1] = weighted_boxes[i, 1] * len(clustered_boxes) / weights.sum()\n",
    "#         overall_boxes.append(weighted_boxes)\n",
    "#     overall_boxes = np.concatenate(overall_boxes, axis=0)\n",
    "#     overall_boxes = overall_boxes[overall_boxes[:, 1].argsort()[::-1]]\n",
    "#     boxes = overall_boxes[:, 4:]\n",
    "#     scores = overall_boxes[:, 1]\n",
    "#     labels = overall_boxes[:, 0]\n",
    "#     return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math as m\n",
    "\n",
    "\n",
    "# # boxes = []\n",
    "# # tile_size = SIZE\n",
    "\n",
    "# def nms_yolo(boxes, thresh):\n",
    "#     '''\n",
    "#     boxes is a numpy array : {n, {x, y, w, h, s, c}}\n",
    "#     thresh is a float: NMS threshold\n",
    "#     '''\n",
    "#     boxes = boxes.copy()\n",
    "\n",
    "#     # x, y, w, h -> x1, y1, x2, y2\n",
    "#     boxes[:, 0] -= boxes[:, 2] / 2\n",
    "#     boxes[:, 1] -= boxes[:, 3] / 2\n",
    "\n",
    "#     boxes[:, 2] += boxes[:, 0]\n",
    "#     boxes[:, 3] += boxes[:, 1]\n",
    "\n",
    "#     scores = boxes[:, 4]\n",
    "\n",
    "#     x1 = boxes[:, 0]\n",
    "#     y1 = boxes[:, 1]\n",
    "#     x2 = boxes[:, 2]\n",
    "#     y2 = boxes[:, 3]\n",
    "\n",
    "#     areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "#     order = scores.argsort()[::-1] # get boxes with more ious first\n",
    "\n",
    "#     keep = []\n",
    "#     while order.size > 0:\n",
    "#         i = order[0] # pick maxmum iou box\n",
    "#         keep.append(i)\n",
    "#         xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "#         yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "#         xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "#         yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "#         w = np.maximum(0.0, xx2 - xx1 + 1) # maximum width\n",
    "#         h = np.maximum(0.0, yy2 - yy1 + 1) # maxiumum height\n",
    "#         area = w * h\n",
    "#         overlap = area / (areas[i] + areas[order[1:]] - area)\n",
    "\n",
    "#         indices = np.where(overlap <= thresh)[0]\n",
    "#         order = order[indices + 1]\n",
    "\n",
    "#     boxes = boxes[keep]\n",
    "\n",
    "#     # x1, y1, x2, y2 -> x, y, w, h\n",
    "#     # boxes[:, 2] -= boxes[:, 0]\n",
    "#     # boxes[:, 3] -= boxes[:, 1]\n",
    "\n",
    "#     # boxes[:, 0] += boxes[:, 2] / 2\n",
    "#     # boxes[:, 1] += boxes[:, 3] / 2\n",
    "\n",
    "#     return boxes  # [boxes[:, 4] >= thresh]\n",
    "\n",
    "\n",
    "# # indices = nms_yolo(boxes_abs[:, :4], boxes_abs[:, 4], 0.175)\n",
    "\n",
    "# # len(indices)\n",
    "\n",
    "# # boxes_sorted = boxes_abs[indices]\n",
    "\n",
    "# # len(boxes_sorted[boxes_sorted[:, 4] >= threshold_nms])\n",
    "\n",
    "# def inference_tiles(session, image, tile_size):\n",
    "#     height, width = image.shape[:2]\n",
    "#     num_patches_x = m.ceil(width / tile_size)\n",
    "#     num_patches_y = m.ceil(height / tile_size)\n",
    "#     bboxes = {}\n",
    "#     # print(f\"Size = {(width, height)}, num patches = {(num_patches_x, num_patches_y)}\")\n",
    "#     offset_x = 0\n",
    "#     for i in range(num_patches_x):\n",
    "#         offset_y = 0\n",
    "#         for j in range(num_patches_y):\n",
    "#             # print(f\"Patch {(i, j)} {(offset_x, offset_y, offset_x + tile_size, offset_y + tile_size)}\")\n",
    "#             # Update y-offset (end of iteration)\n",
    "#             shift_y = ((num_patches_y - j) - (height - offset_y) / tile_size) / (num_patches_y - j - 1 + 1e-15)\n",
    "#             offset_y += round(tile_size - tile_size * shift_y)\n",
    "#             batch = np.moveaxis(image, -1, 0)[None, ...] / np.float32(255)\n",
    "#             predictions = session.run(None, {session.get_inputs()[0].name: batch})[0][0]\n",
    "#             print(f\"Patch {i, j}: {len(predictions)} predictions (no NMS)\")\n",
    "#             predictions = nms_yolo(predictions, 0.25)\n",
    "#             print(f\"Patch {i, j}: {len(predictions)} predictions (with NMS)\")\n",
    "#             # Filter border-overlap boxes\n",
    "#             index_border_overlap = (((predictions[:, 0] <= 0) & (i > 0)) |\n",
    "#                                     ((predictions[:, 1] <= 0) & (j > 0)) |\n",
    "#                                     ((predictions[:, 2] >= tile_size) & (i < (num_patches_x - 1))) |\n",
    "#                                     ((predictions[:, 3] >= tile_size) & (j < (num_patches_y - 1))))\n",
    "#             print(f\"{i, j} overlaps = {index_border_overlap.sum()}\")\n",
    "#             predictions = predictions[~index_border_overlap]\n",
    "#             # Patch box position (relative) to image box position (absolute)\n",
    "#             predictions[:, 0:4:2] += offset_x\n",
    "#             predictions[:, 1:4:2] += offset_y\n",
    "#             boxes = {\n",
    "#                 (i, j): {\n",
    "#                     'predictions': predictions,\n",
    "#                     'offset_x': offset_x,\n",
    "#                     'offset_y': offset_y\n",
    "#                 }\n",
    "#             }\n",
    "#         # Update x-offset (end of iteration)\n",
    "#         shift_x = ((num_patches_x - i) - (width - offset_x) / tile_size) / (num_patches_x - i - 1 + 1e-15)\n",
    "#         offset_x += round(tile_size - tile_size * shift_x)\n",
    "#     return boxes\n",
    "\n",
    "# def wbf(outputs, weights, thresh_iou, thresh_conf, conf_type='max'):\n",
    "#     # Sort by score\n",
    "#     boxes_clusters = []\n",
    "#     boxes_fused = []\n",
    "#     boxes =[]\n",
    "\n",
    "#     return boxes\n",
    "\n",
    "# for filename in sorted(glob(osp.join(PATH_DATA, '*'))):\n",
    "#     video = cv.VideoCapture(filename)\n",
    "#     try:\n",
    "#         if video.isOpened():\n",
    "#             height, width = video.get(cv.CAP_PROP_FRAME_HEIGHT), video.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "#             step_y, step_x = get_tile_step((height, width), SIZE)\n",
    "#             print(f\"Tile steps = {step_y, step_x}\")\n",
    "#             while True:\n",
    "#                 ok, frame = video.read()\n",
    "#                 if not ok:\n",
    "#                     break\n",
    "#                 # slices = ImageSlicer(image_shape=frame.shape[:2], tile_size=SIZE, tile_step=(step_y, step_x))\n",
    "#                 # slices.split(frame)\n",
    "#                 # for image, coordinates in slices.iter_split(frame):\n",
    "#                 #     print(f\"Tile coordinates = {coordinates}\")\n",
    "#                 image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "#                 # batch = np.moveaxis(image, -1, 0)[None, ...] / np.float32(255)\n",
    "#                 # boxes += session.run(None, {session.get_inputs()[0].name: batch})[0][0]\n",
    "#                 boxes = inference_tiles(session, image, SIZE)\n",
    "#                 boxes = wbf(np.array([box['predictions'] for box in boxes]), np.array([1] * len(boxes)))\n",
    "#                 break\n",
    "#     finally:\n",
    "#         video.release()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
